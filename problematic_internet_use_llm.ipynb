{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b738c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a961ffb",
   "metadata": {},
   "source": [
    "Importacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='data'):\n",
    "    \"\"\"Carga datos desde la carpeta 'data' con paths relativos seguros\"\"\"\n",
    "    try:\n",
    "        # Verifica existencia de archivos\n",
    "        train_csv_path = os.path.join(data_dir, 'train.csv')\n",
    "        test_csv_path = os.path.join(data_dir, 'test.csv')\n",
    "        train_parquet_path = os.path.join(data_dir, 'train.parquet')\n",
    "        test_parquet_path = os.path.join(data_dir, 'test.parquet')\n",
    "        \n",
    "        if not all(os.path.exists(f) for f in [train_csv_path, test_csv_path]):\n",
    "            raise FileNotFoundError(\"Archivos CSV no encontrados en la carpeta 'data'\")\n",
    "        \n",
    "        # Carga CSV\n",
    "        train_csv = pd.read_csv(train_csv_path)\n",
    "        test_csv = pd.read_csv(test_csv_path)\n",
    "        \n",
    "        # Carga Parquet si existen\n",
    "        train_parquet = pd.DataFrame()\n",
    "        test_parquet = pd.DataFrame()\n",
    "        if os.path.exists(train_parquet_path):\n",
    "            train_parquet = pq.read_table(train_parquet_path).to_pandas()\n",
    "        if os.path.exists(test_parquet_path):\n",
    "            test_parquet = pq.read_table(test_parquet_path).to_pandas()\n",
    "        \n",
    "        # Combina datos\n",
    "        train = pd.merge(train_csv, train_parquet, on='Subject_ID', how='left') if not train_parquet.empty else train_csv\n",
    "        test = pd.merge(test_csv, test_parquet, on='Subject_ID', how='left') if not test_parquet.empty else test_csv\n",
    "        \n",
    "        return train, test, {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error cargando datos: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b0b84",
   "metadata": {},
   "source": [
    "Hacer feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_actigraphy(df, subject_id_col='Subject_ID'):\n",
    "    \"\"\"\n",
    "    Enhanced actigraphy processing with:\n",
    "    - Percentiles (10th, 25th, 75th, 90th)\n",
    "    - Robust statistical measures (IQR, MAD)\n",
    "    - Frequency domain features (FFT)\n",
    "    \"\"\"\n",
    "    exclude_cols = [subject_id_col, 'timestamp']\n",
    "    num_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols \n",
    "               and pd.api.types.is_numeric_dtype(df[col])]\n",
    "    \n",
    "    # Time-domain features\n",
    "    stats = {\n",
    "        'mean': np.mean,\n",
    "        'std': np.std,\n",
    "        'min': np.min,\n",
    "        'max': np.max,\n",
    "        'median': np.median,\n",
    "        'skew': skew,\n",
    "        'kurtosis': kurtosis,\n",
    "        'q1': lambda x: np.percentile(x, 25),\n",
    "        'q3': lambda x: np.percentile(x, 75),\n",
    "        'iqr': lambda x: np.percentile(x, 75) - np.percentile(x, 25),\n",
    "        'mad': lambda x: np.median(np.abs(x - np.median(x)))\n",
    "    }\n",
    "    \n",
    "    # Frequency-domain features (simplified FFT)\n",
    "    def dominant_freq(x):\n",
    "        if len(x) < 2: return 0\n",
    "        fft = np.abs(np.fft.fft(x))\n",
    "        return np.argmax(fft[1:len(fft)//2]) + 1\n",
    "    \n",
    "    summary = df.groupby(subject_id_col)[num_cols].agg(stats)\n",
    "    summary.columns = [f'{col}_{stat}' for col, stat in summary.columns]\n",
    "    \n",
    "    # Add frequency features\n",
    "    freq_features = df.groupby(subject_id_col)[num_cols].agg(dominant_freq)\n",
    "    freq_features.columns = [f'{col}_dominant_freq' for col in freq_features.columns]\n",
    "    \n",
    "    return pd.concat([summary, freq_features], axis=1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f233bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(df, subject_col='Subject_ID'):\n",
    "    \"\"\"Extrae 15 features temporales clave por sujeto\"\"\"\n",
    "    features = []\n",
    "    for subject_id, group in df.groupby(subject_col):\n",
    "        if 'timestamp' in group.columns:\n",
    "            time_diff = group['timestamp'].diff().dt.total_seconds()\n",
    "            feat = {\n",
    "                'Subject_ID': subject_id,\n",
    "                'total_events': len(group),\n",
    "                'active_hours': (time_diff < 3600).sum(),\n",
    "                'night_activity': group[group['timestamp'].dt.hour.between(0, 6)]['value'].mean(),\n",
    "                'max_activity': group['value'].max(),\n",
    "                'std_activity': group['value'].std(),\n",
    "            }\n",
    "            features.append(feat)\n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eecd3",
   "metadata": {},
   "source": [
    "Complete the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0663ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Utility functions for competition submission\n",
    "'''\n",
    "\n",
    "def save_submission(test, preds, output_dir):\n",
    "    '''\n",
    "    Saves predictions in Kaggle submission format\n",
    "    \n",
    "    Args:\n",
    "        test: Test DataFrame\n",
    "        preds: Model predictions\n",
    "        output_dir: Directory to save submission file\n",
    "    '''\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test['id'],\n",
    "        'sii': preds\n",
    "    })\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    submission_path = os.path.join(output_dir, 'submission.csv')\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission saved to {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
